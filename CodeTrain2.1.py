import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from scipy.signal import savgol_filter
from scipy.ndimage import median_filter
import matplotlib.pyplot as plt

# --- THI·∫æT L·∫¨P THI·∫æT B·ªä ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üöÄ Chi·∫øn th·∫ßn ƒëang ch·∫°y tr√™n: {device}")


# ==========================================
# 1. KI·∫æN TR√öC RESNET 1D (Gi·ªØ nguy√™n v√¨ n√≥ r·∫•t b√°)
# ==========================================
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ResidualBlock, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(),
            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm1d(out_channels)
        )
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv1d(in_channels, out_channels, kernel_size=1),
                nn.BatchNorm1d(out_channels)
            )

    def forward(self, x):
        return torch.relu(self.conv(x) + self.shortcut(x))


class SugarResNet(nn.Module):
    def __init__(self, num_targets=4):
        super(SugarResNet, self).__init__()
        self.feature_extractor = nn.Sequential(
            nn.Conv1d(3, 64, kernel_size=7, stride=2, padding=3),
            nn.ReLU(),
            ResidualBlock(64, 64),
            ResidualBlock(64, 128),
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten()
        )
        self.regressor = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, num_targets)
        )

    def forward(self, x):
        features = self.feature_extractor(x)
        return self.regressor(features)


# ==========================================
# 2. H√ÄM TI·ªÄN X·ª¨ L√ù SI√äU C·∫§P (Data Cleaning & Prep)
# ==========================================
def prepare_data_v2():
    print("üìÇ ƒêang n·∫°p d·ªØ li·ªáu v√† thanh l·ªçc...")

    # ƒê·ªçc Spectra (H√†ng l√† Wavenumber, C·ªôt l√† Sample)
    df_spec = pd.read_csv('Sugar_Concentration_Test_ALL_spectra.csv', index_col=0)
    X_raw = df_spec.T  # Xoay ngang: H√†ng l√† M·∫´u

    # ƒê·ªçc Metadata ƒë·ªÉ l·∫•y nh√£n
    df_meta = pd.read_csv('Sugar_Concentrations.xlsx - Sheet1 (2).csv')

    # --- B∆Ø·ªöC 1: TRUY T√åM V√Ä TR·∫¢M M·∫™U L·ªñI ---
    # Qu√©t v√πng pixel nghi v·∫•n (v√≠ d·ª• 1400-1650) ƒë·ªÉ t√¨m 'c·ªôt ƒë√¨nh' > 2000
    mask_sach = np.all(X_raw.iloc[:, 1400:1650] < 2000, axis=1)
    X_clean_df = X_raw[mask_sach]

    print(f"‚úÖ ƒê√£ d·ªçn r√°c! Lo·∫°i b·ªè {len(X_raw) - len(X_clean_df)} m·∫´u nhi·ªÖu n·∫∑ng.")

    black_list = ['E3_3', 'E4_3']
    def check_not_outlier(sample_name):
        parts = sample_name.split('_')
        cell_id = f"{parts[4]}_{parts[5]}"
        return cell_id not in black_list

    mask_khong_outlier = [check_not_outlier(name) for name in X_clean_df.index]
    X_clean_df = X_clean_df[mask_khong_outlier]

    print(f"‚úÇÔ∏è ƒê√£ g·∫∑t b·ªè th√™m c√°c m·∫´u Outliers t·ª´ gi·∫øng: {black_list}")
    print(f"üìä S·ªë l∆∞·ª£ng m·∫´u c√≤n l·∫°i ƒë·ªÉ hu·∫•n luy·ªán: {len(X_clean_df)}")

    # --- B∆Ø·ªöC 2: KH·ªöP NH√ÉN (GROUND TRUTH) ---
    target_cols = ['Sucrose [ul]', 'Fructose [ul]', 'Maltose [ul]', 'Glucose [ul]']
    y_list = []
    X_final_list = []

    for sample_name in X_clean_df.index:
        try:
            # Gi·∫£i m√£ Cell ID: Sugar_Concentration_Test_54_E6_2_... -> E6_2
            parts = sample_name.split('_')
            cell_id = f"{parts[4]}_{parts[5]}"

            # L·∫•y n·ªìng ƒë·ªô t·ª´ Metadata
            row = df_meta[df_meta['Cell Number'] == cell_id]
            if not row.empty:
                y_list.append(row[target_cols].values[0])
                X_final_list.append(X_clean_df.loc[sample_name].values)
        except:
            continue

    X_final = np.array(X_final_list)
    y_final = np.array(y_list)

    # --- B∆Ø·ªöC 3: TI·ªÄN X·ª¨ L√ù QUANG PH·ªî ---
    # 1. L·ªçc gai (Median filter)
    X_despiked = median_filter(X_final, size=(1, 3))

    # 2. T√≠nh ƒë·∫°o h√†m (Savgol)
    d1 = savgol_filter(X_despiked, window_length=15, polyorder=3, deriv=1)
    d2 = savgol_filter(X_despiked, window_length=15, polyorder=3, deriv=2)

    # 3. Chu·∫©n h√≥a SNV
    def snv(data):
        return (data - np.mean(data, axis=1, keepdims=True)) / (np.std(data, axis=1, keepdims=True) + 1e-8)

    # G·ªôp 3 k√™nh v√† chu·∫©n h√≥a Y v·ªÅ d·∫£i 0-1 (375ul l√† Max)
    X_processed = np.stack([snv(X_despiked), snv(d1), snv(d2)], axis=1)
    y_scaled = y_final / 375.0

    print(f"üìä Dataset s·∫°ch: {len(X_processed)} m·∫´u. S·∫µn s√†ng luy·ªán c√¥ng!")
    return train_test_split(X_processed, y_scaled, test_size=0.15, random_state=42), y_final


# ==========================================
# 3. HU·∫§N LUY·ªÜN CHI·∫æN TH·∫¶N
# ==========================================
(X_train, X_test, y_train, y_test_scaled), y_original = prepare_data_v2()

train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))
train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)

model = SugarResNet().to(device)
criterion = nn.L1Loss()  # D√πng L1 (MAE) ƒë·ªÉ x·ª≠ l√Ω Bias t·ªët h∆°n MSE
optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)

print("\n--- B·∫Øt ƒë·∫ßu luy·ªán t·∫≠p ResNet v2.0 ---")
for epoch in range(120):  # TƒÉng l√™n t√≠ cho ch√≠n
    model.train()
    epoch_loss = 0
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        epoch_loss += loss.item()

    avg_loss = epoch_loss / len(train_loader)
    scheduler.step(avg_loss)

    if (epoch + 1) % 20 == 0:
        print(f"üî• Epoch {epoch + 1:03d} | Loss: {avg_loss:.6f} | LR: {optimizer.param_groups[0]['lr']}")

# ==========================================
# 4. ƒê√ÅNH GI√Å (QUY ƒê·ªîI NG∆Ø·ª¢C V·ªÄ UL)
# ==========================================
model.eval()
with torch.no_grad():
    X_test_torch = torch.tensor(X_test, dtype=torch.float32).to(device)
    preds_scaled = model(X_test_torch).cpu().numpy()

    # Quy ƒë·ªïi ng∆∞·ª£c v·ªÅ ƒë∆°n v·ªã ul
    preds_ul = preds_scaled * 375.0
    y_test_ul = y_test_scaled * 375.0

# V·∫Ω bi·ªÉu ƒë·ªì so s√°nh t·ªïng h·ª£p
sugar_names = ['Sucrose', 'Fructose', 'Maltose', 'Glucose']
plt.figure(figsize=(18, 4))
for i in range(4):
    plt.subplot(1, 4, i + 1)
    r_val = np.corrcoef(y_test_ul[:, i], preds_ul[:, i])[0, 1]
    bias = np.mean(preds_ul[:, i] - y_test_ul[:, i])

    plt.scatter(y_test_ul[:, i], preds_ul[:, i], alpha=0.4, color='darkorange')
    plt.plot([0, 150], [0, 150], 'k--', lw=1)
    plt.title(f"{sugar_names[i]}\nR={r_val:.3f} | Bias={bias:+.2f}")
    plt.xlabel("Th·ª±c t·∫ø (ul)")
    plt.ylabel("D·ª± ƒëo√°n (ul)")
    plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# L∆∞u Model "H·ªãn"
torch.save(model.state_dict(), 'raman_resnet_v2.pth')
print("\n‚úÖ ƒê√£ l∆∞u model v2.0. ƒê·∫°i ca mang sang App d√πng ngay cho n√≥ng!")