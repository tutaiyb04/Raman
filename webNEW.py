import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from scipy.signal import savgol_filter
from scipy.ndimage import median_filter
import re

# ==========================================
# 1. KIáº¾N TRÃšC Máº NG RESNET (Giá»¯ nguyÃªn v2.1)
# ==========================================
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ResidualBlock, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm1d(out_channels),
            nn.ReLU(),
            nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm1d(out_channels)
        )
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv1d(in_channels, out_channels, kernel_size=1),
                nn.BatchNorm1d(out_channels)
            )
    def forward(self, x):
        return torch.relu(self.conv(x) + self.shortcut(x))

class RamanResNet(nn.Module):
    def __init__(self, num_targets=4):
        super(RamanResNet, self).__init__()
        self.feature_extractor = nn.Sequential(
            nn.Conv1d(3, 64, kernel_size=7, stride=2, padding=3),
            nn.ReLU(),
            ResidualBlock(64, 64),
            ResidualBlock(64, 128),
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten()
        )
        self.regressor = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, num_targets)
        )
    def forward(self, x):
        features = self.feature_extractor(x)
        return self.regressor(features)

# ==========================================
# 2. HÃ€M TIá»€N Xá»¬ LÃ (Äá»“ng bá»™ v2.1)
# ==========================================
def preprocess_input(spectrum):
    clean = median_filter(spectrum, size=3)
    x = clean.reshape(1, -1)
    d1 = savgol_filter(x, window_length=15, polyorder=3, deriv=1)
    d2 = savgol_filter(x, window_length=15, polyorder=3, deriv=2)
    def snv(data):
        return (data - np.mean(data, axis=1, keepdims=True)) / (np.std(data, axis=1, keepdims=True) + 1e-8)
    x_proc = np.stack([snv(x), snv(d1), snv(d2)], axis=1)
    return torch.tensor(x_proc, dtype=torch.float32)

# ==========================================
# 3. Cáº¤U HÃŒNH & LOAD DATA
# ==========================================
st.set_page_config(page_title="Raman Analyzer Pro v2.2", layout="wide")
MODEL_PATH = 'raman_resnet_experiment.pth'
METADATA_PATH = 'Sugar_Concentrations.csv'

@st.cache_resource
def load_model():
    model = RamanResNet(num_targets=4)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))
    model.eval()
    return model

@st.cache_data
def load_meta():
    return pd.read_csv(METADATA_PATH)

try:
    model = load_model()
    df_meta = load_meta()
except Exception as e:
    st.error(f"âš ï¸ Lá»—i há»‡ thá»‘ng: {e}")
    st.stop()

# ==========================================
# 4. SIDEBAR - Bá»˜ Lá»ŒC THÃ”NG MINH
# ==========================================
st.sidebar.header("ğŸ›  Äiá»u khiá»ƒn & TÃ¬m kiáº¿m")
uploaded_file = st.sidebar.file_uploader("1. Táº£i file Spectra (.csv)", type="csv")

selected_sample = None

if uploaded_file:
    df_spec = pd.read_csv(uploaded_file)
    all_samples = df_spec.columns[1:].tolist()
    
    tab_search, tab_list = st.sidebar.tabs(["ğŸ” TÃ¬m theo Giáº¿ng", "ğŸ“‹ Danh sÃ¡ch gá»‘c"])
    
    with tab_list:
        selected_sample = st.selectbox("Chá»n tá»« danh sÃ¡ch cuá»™n:", all_samples)

    with tab_search:
        # PhÃ¢n tÃ¡ch tÃªn máº«u Ä‘á»ƒ táº¡o bá»™ lá»c (Regex Ä‘á»ƒ báº¯t E4_3, v.v.)
        # TÃªn máº«u: Sugar_Concentration_Test_52_E4_3_RD1_M1_R2
        try:
            # Láº¥y danh sÃ¡ch Plate duy nháº¥t
            plates = sorted(list(set([s.split('_')[5] for s in all_samples])))
            sel_plate = st.selectbox("Chá»n Plate:", plates)
            
            # Lá»c cÃ¡c máº«u thuá»™c Plate Ä‘Ã³
            plate_samples = [s for s in all_samples if s.split('_')[5] == sel_plate]
            
            # Láº¥y danh sÃ¡ch HÃ ng (A-H)
            rows = sorted(list(set([re.findall(r'[A-Z]', s.split('_')[4])[0] for s in plate_samples])))
            sel_row = st.select_slider("Chá»n HÃ ng (Row):", options=rows)
            
            # Lá»c theo hÃ ng
            row_samples = [s for s in plate_samples if s.split('_')[4].startswith(sel_row)]
            
            # Láº¥y danh sÃ¡ch Cá»™t (1-12)
            cols = sorted(list(set([int(re.findall(r'\d+', s.split('_')[4])[0]) for s in row_samples])))
            sel_col = st.selectbox("Chá»n Cá»™t (Column):", cols)
            
            # Láº¥y láº§n láº·p (Round/Rep)
            final_options = [s for s in row_samples if s.split('_')[4] == f"{sel_row}{sel_col}"]
            
            if final_options:
                selected_sample = st.radio("Chá»n láº§n Ä‘o (Replicates):", final_options)
            else:
                st.warning("KhÃ´ng tÃ¬m tháº¥y máº«u phÃ¹ há»£p.")
        except:
            st.error("Cáº¥u trÃºc tÃªn file khÃ´ng khá»›p vá»›i bá»™ lá»c thÃ´ng minh.")

# ==========================================
# 5. HIá»‚N THá»Š Káº¾T QUáº¢ (NhÆ° cÅ© nhÆ°ng á»•n Ä‘á»‹nh hÆ¡n)
# ==========================================
if uploaded_file and selected_sample:
    spectrum = df_spec[selected_sample].values
    wavenumbers = df_spec.iloc[:, 0].values

    st.title(f"ğŸ”¬ PhÃ¢n tÃ­ch máº«u: {selected_sample}")
    col_plot, col_res = st.columns([1.3, 1])

    with col_plot:
        st.subheader("ğŸ“ˆ Äá»“ thá»‹ phá»• Raman")
        fig, ax = plt.subplots(figsize=(10, 5))
        ax.plot(wavenumbers, spectrum, color='lightgray', lw=1, label='Raw', alpha=0.5)
        clean = median_filter(spectrum, size=3)
        ax.plot(wavenumbers, clean, color='#008080', lw=1.5, label='Median Filtered')
        ax.set_xlabel("Wavenumber (cm-1)")
        ax.set_ylabel("Intensity")
        ax.legend()
        st.pyplot(fig)

    with col_res:
        st.subheader("ğŸ“Š Káº¿t quáº£ AI vs Metadata")
        input_tensor = preprocess_input(spectrum)
        with torch.no_grad():
            preds = np.maximum(model(input_tensor).numpy()[0] * 375.0, 0)
        
        sugars = ["Sucrose", "Fructose", "Maltose", "Glucose"]
        target_cols = [f'{s} [ul]' for s in sugars]
        
        parts = selected_sample.split('_')
        cell_id = f"{parts[4]}_{parts[5]}"
        truth_row = df_meta[df_meta['Cell Number'] == cell_id]

        if not truth_row.empty:
            actuals = truth_row[target_cols].values[0]
            compare_df = pd.DataFrame({
                "ThÃ nh pháº§n": sugars,
                "Thá»±c táº¿": np.round(actuals, 2),
                "AI Dá»± Ä‘oÃ¡n": np.round(preds, 2),
                "Lá»‡ch": np.round(preds - actuals, 2)
            })
            st.table(compare_df)
            st.success(f"ğŸ’ MAE: {np.mean(np.abs(preds-actuals)):.2f} Âµl")
        else:
            for s, p in zip(sugars, preds):
                st.metric(s, f"{p:.2f} Âµl")

    # Báº£ng Metrics hiá»‡u nÄƒng v2.1
    with st.expander("ğŸ“ ThÃ´ng sá»‘ hiá»‡u nÄƒng há»‡ thá»‘ng (Model v2.1)"):
        st.table(pd.DataFrame({
            "ÄÆ°á»ng": sugars,
            "MAE": [2.77, 2.59, 2.76, 4.41],
            "R-squared": [0.9927, 0.9967, 0.9964, 0.9931]
        }))
else:
    st.info("ğŸ‘‹ ChÃ o Ä‘áº¡i ca! HÃ£y táº£i file CSV lÃªn Ä‘á»ƒ tráº£i nghiá»‡m bá»™ lá»c tÃ¬m kiáº¿m má»›i.")

